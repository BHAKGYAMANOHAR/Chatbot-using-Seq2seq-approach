{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VkrUygIEoj8j"
   },
   "source": [
    "# **PROJECT SUNRISE**\n",
    "## **Theme : Conversational AI Project #1**\n",
    "**Goal: Build a task oriented conversational model using seq2seq without attention approach**\n",
    "\n",
    "ML Framework : Tensorflow 2.0\n",
    "\n",
    "Dataset : https://research.fb.com/downloads/babi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwQL8XP8WjyU"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjvPT1Fepv6_"
   },
   "outputs": [],
   "source": [
    "# Setting the hyperparameters\n",
    "batch_size = 64  \n",
    "epochs = 100  \n",
    "rnn_size = 512  \n",
    "VOCAB_SIZE = 151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B321xPiwqByU"
   },
   "outputs": [],
   "source": [
    "# Path to the data txt file on disk.\n",
    "data_path = 'G:\\Mini Project I\\Datasets\\Dataset.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ur9rX-_3qRJl"
   },
   "source": [
    "## **Loading and preprocessing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ti_8BNcNXGo1"
   },
   "outputs": [],
   "source": [
    "# Separate the user and bot utterances from the dataset\n",
    "def load_dataset(path):\n",
    "  user_utterances = []\n",
    "  bot_utterances = []\n",
    "  input_characters = set()\n",
    "  target_characters = set()\n",
    "  with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "  for line in lines:\n",
    "    if '\\t' not in line:\n",
    "      continue\n",
    "    _user_utterance, _bot_utterance = line.rstrip().split('\\t')\n",
    "    _user_utterance = _user_utterance.split(\" \",1)\n",
    "    input_text = _user_utterance[1]\n",
    "    user_utterances.append(input_text)\n",
    "    bot_utterances.append(_bot_utterance)\n",
    "  return user_utterances, bot_utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qpc-AIUMis0f"
   },
   "outputs": [],
   "source": [
    "# Put <BOS> tag and <EOS> tag for bot utterances \n",
    "def tagger(bot_utterances):\n",
    "  bos = \"<BOS> \"\n",
    "  eos = \" <EOS>\"\n",
    "  tagged_target = [bos + text + eos for text in bot_utterances] \n",
    "  return  tagged_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tn2QBRzF3dfT"
   },
   "outputs": [],
   "source": [
    "# Doing a first cleaning of the texts\n",
    "def clean_text(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(r\"[-()\\\"#/@;:<>{}+=~|.?,_]\", \"\", text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-vVc59fiBhO"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-59cd832b69b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclean_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muser_utterances\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mclean_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Cleaning the bot utterances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclean_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-497f8d19b3e8>\u001b[0m in \u001b[0;36mclean_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"[-()\\\"#/@;:<>{}+=~|.?,_]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "user_utterances, bot_utterances = load_dataset(data_path)\n",
    "bot_utterances = tagger(bot_utterances)\n",
    "# Cleaning the user utterances\n",
    "clean_input = []\n",
    "for text in user_utterances:\n",
    "    clean_input.append(clean_text(text))\n",
    "# Cleaning the bot utterances\n",
    "clean_target = []\n",
    "for text in bot_utterances:\n",
    "    clean_target.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NdbMqpaPuCa7"
   },
   "source": [
    "## **Making Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l6mbETxHj31-"
   },
   "outputs": [],
   "source": [
    "def vocab_creater(text_lists, VOCAB_SIZE):\n",
    "\n",
    "  tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)\n",
    "  tokenizer.fit_on_texts(text_lists)\n",
    "  dictionary = tokenizer.word_index\n",
    "  \n",
    "  word2idx = {}\n",
    "  idx2word = {}\n",
    "  for k, v in dictionary.items():\n",
    "      if v < VOCAB_SIZE:\n",
    "          word2idx[k] = v\n",
    "          idx2word[v] = k\n",
    "      if v >= VOCAB_SIZE-1:\n",
    "          continue\n",
    "          \n",
    "  return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "dMHw8S2huNCc",
    "outputId": "d692bbce-e3fe-4566-a891-1421ac21c4e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'silence': 1, 'in': 2, 'a': 3, 'for': 4, 'with': 5, 'price': 6, 'range': 7, 'i': 8, 'you': 9, 'table': 10, 'food': 11, 'be': 12, 'cuisine': 13, 'people': 14, 'instead': 15, 'could': 16, 'it': 17, 'actually': 18, 'would': 19, 'prefer': 20, 'book': 21, 'can': 22, 'please': 23, 'no': 24, 'cheap': 25, 'expensive': 26, 'moderate': 27, 'restaurant': 28, 'hello': 29, 'hi': 30, 'good': 31, 'morning': 32, 'four': 33, 'six': 34, 'eight': 35, 'two': 36, 'british': 37, 'london': 38, 'madrid': 39, 'italian': 40, 'paris': 41, 'french': 42, \"i'd\": 43, 'like': 44, 'to': 45, 'may': 46, 'have': 47, 'rome': 48, 'spanish': 49, 'bombay': 50, 'indian': 51, 'make': 52, 'reservation': 53, 'thanks': 54, 'thank': 55, 'rock': 56, 'am': 57, 'looking': 58, 'we': 59, 'will': 60, 'love': 61, ' ': 62}\n",
      "{1: 'bos', 2: 'eos', 3: 'you', 4: 'for', 5: 'ok', 6: 'let', 7: 'me', 8: 'look', 9: 'into', 10: 'some', 11: 'options', 12: 'apicall', 13: 'it', 14: 'on', 15: 'sure', 16: 'is', 17: 'there', 18: 'anything', 19: 'else', 20: 'to', 21: 'update', 22: 'hello', 23: 'what', 24: 'can', 25: 'i', 26: 'help', 27: 'with', 28: 'today', 29: \"i'm\", 30: 'be', 31: 'cheap', 32: 'expensive', 33: 'moderate', 34: \"you're\", 35: 'welcome', 36: 'four', 37: 'six', 38: 'eight', 39: 'two', 40: 'british', 41: 'london', 42: 'paris', 43: 'madrid', 44: 'italian', 45: 'french', 46: 'rome', 47: 'indian', 48: 'bombay', 49: 'spanish', 50: 'where', 51: 'should', 52: 'which', 53: 'price', 54: 'range', 55: 'are', 56: 'looking', 57: 'how', 58: 'many', 59: 'people', 60: 'would', 61: ' ', 62: 'your', 63: 'party', 64: 'any', 65: 'preference', 66: 'a', 67: 'type', 68: 'of', 69: 'cuisine'}\n"
     ]
    }
   ],
   "source": [
    "input_token_index, index_input_token = vocab_creater(clean_input, VOCAB_SIZE)\n",
    "input_token_index[' '] = len(input_token_index)+1\n",
    "index_input_token[len(index_input_token)+1] = ' '\n",
    "target_token_index, index_target_token = vocab_creater(clean_target, VOCAB_SIZE)\n",
    "target_token_index[' '] = len(target_token_index)+1\n",
    "index_target_token[len(index_target_token)] = ' '\n",
    "print(input_token_index)\n",
    "print(index_target_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "rIhOB5uxl_qO",
    "outputId": "d55dcec4-1e7a-4ff2-a176-bf88388dc75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['silence', 'in', 'a', 'for', 'with', 'price', 'range', 'i', 'you', 'table', 'food', 'be', 'cuisine', 'people', 'instead', 'could', 'it', 'actually', 'would', 'prefer', 'book', 'can', 'please', 'no', 'cheap', 'expensive', 'moderate', 'restaurant', 'hello', 'hi', 'good', 'morning', 'four', 'six', 'eight', 'two', 'british', 'london', 'madrid', 'italian', 'paris', 'french', \"i'd\", 'like', 'to', 'may', 'have', 'rome', 'spanish', 'bombay', 'indian', 'make', 'reservation', 'thanks', 'thank', 'rock', 'am', 'looking', 'we', 'will', 'love', ' '])\n",
      "dict_keys(['bos', 'eos', 'you', 'for', 'ok', 'let', 'me', 'look', 'into', 'some', 'options', 'apicall', 'it', 'on', 'sure', 'is', 'there', 'anything', 'else', 'to', 'update', 'hello', 'what', 'can', 'i', 'help', 'with', 'today', \"i'm\", 'be', 'cheap', 'expensive', 'moderate', \"you're\", 'welcome', 'four', 'six', 'eight', 'two', 'british', 'london', 'paris', 'madrid', 'italian', 'french', 'rome', 'indian', 'bombay', 'spanish', 'where', 'should', 'which', 'price', 'range', 'are', 'looking', 'how', 'many', 'people', 'would', 'in', 'your', 'party', 'any', 'preference', 'a', 'type', 'of', 'cuisine', ' '])\n",
      "19\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "input_words = []\n",
    "target_words = []\n",
    "input_words = input_token_index.keys()\n",
    "target_words = target_token_index.keys()\n",
    "num_encoder_tokens = len(input_words)\n",
    "num_decoder_tokens = len(target_words)\n",
    "max_encoder_seq_length = max([len(txt.split()) for txt in clean_input])\n",
    "max_decoder_seq_length = max([len(txt.split()) for txt in clean_target])\n",
    "print(input_words)\n",
    "print(target_words)\n",
    "print(max_encoder_seq_length)\n",
    "print(max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "iMCdCYUPbVIL",
    "outputId": "be976b67-0f75-4824-b8e7-4e6c2e38501c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 40635\n",
      "Number of unique input tokens: 62\n",
      "Number of unique output tokens: 70\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(clean_input))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhZeSbw2ay8h"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(user_utterances), max_encoder_seq_length, num_encoder_tokens+1),dtype='float32')\n",
    "decoder_input_data = np.zeros((len(user_utterances), max_decoder_seq_length, num_decoder_tokens+1),dtype='float32')\n",
    "decoder_target_data = np.zeros((len(user_utterances), max_decoder_seq_length, num_decoder_tokens+1),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTyiflNZbud0"
   },
   "outputs": [],
   "source": [
    "#Teacher forcing method\n",
    "for i, (input_text, target_text) in enumerate(zip(clean_input, clean_target)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "      encoder_input_data[i, t, input_token_index[word]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "      decoder_input_data[i, t, target_token_index[word]] = 1.\n",
    "      if t > 0:\n",
    "        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0Uosn6R6r0Wj",
    "outputId": "a1ecd8a7-c910-4061-e4c2-cec348835305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "508/508 [==============================] - 15s 29ms/step - loss: 0.5821 - accuracy: 0.8270 - val_loss: 0.1442 - val_accuracy: 0.9332\n",
      "Epoch 2/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1565 - accuracy: 0.9297 - val_loss: 0.1375 - val_accuracy: 0.9325\n",
      "Epoch 3/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1530 - accuracy: 0.9306 - val_loss: 0.2405 - val_accuracy: 0.9133\n",
      "Epoch 4/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1483 - accuracy: 0.9315 - val_loss: 0.1362 - val_accuracy: 0.9331\n",
      "Epoch 5/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1545 - accuracy: 0.9294 - val_loss: 0.1358 - val_accuracy: 0.9328\n",
      "Epoch 6/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1486 - accuracy: 0.9314 - val_loss: 0.1353 - val_accuracy: 0.9326\n",
      "Epoch 7/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1458 - accuracy: 0.9318 - val_loss: 0.1358 - val_accuracy: 0.9331\n",
      "Epoch 8/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1454 - accuracy: 0.9319 - val_loss: 0.1366 - val_accuracy: 0.9330\n",
      "Epoch 9/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1458 - accuracy: 0.9317 - val_loss: 0.1357 - val_accuracy: 0.9320\n",
      "Epoch 10/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1448 - accuracy: 0.9326 - val_loss: 0.1376 - val_accuracy: 0.9328\n",
      "Epoch 11/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1434 - accuracy: 0.9322 - val_loss: 0.1349 - val_accuracy: 0.9324\n",
      "Epoch 12/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1434 - accuracy: 0.9327 - val_loss: 0.1366 - val_accuracy: 0.9325\n",
      "Epoch 13/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1870 - accuracy: 0.9299 - val_loss: 0.1365 - val_accuracy: 0.9329\n",
      "Epoch 14/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1437 - accuracy: 0.9327 - val_loss: 0.1352 - val_accuracy: 0.9325\n",
      "Epoch 15/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1441 - accuracy: 0.9327 - val_loss: 0.1566 - val_accuracy: 0.9236\n",
      "Epoch 16/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1444 - accuracy: 0.9323 - val_loss: 0.1357 - val_accuracy: 0.9326\n",
      "Epoch 17/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1445 - accuracy: 0.9324 - val_loss: 0.1358 - val_accuracy: 0.9329\n",
      "Epoch 18/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1434 - accuracy: 0.9328 - val_loss: 0.1368 - val_accuracy: 0.9329\n",
      "Epoch 19/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1440 - accuracy: 0.9327 - val_loss: 0.1359 - val_accuracy: 0.9331\n",
      "Epoch 20/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1432 - accuracy: 0.9328 - val_loss: 0.1348 - val_accuracy: 0.9327\n",
      "Epoch 21/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1431 - accuracy: 0.9327 - val_loss: 0.1343 - val_accuracy: 0.9335\n",
      "Epoch 22/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1452 - accuracy: 0.9327 - val_loss: 0.1350 - val_accuracy: 0.9326\n",
      "Epoch 23/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1430 - accuracy: 0.9329 - val_loss: 0.1360 - val_accuracy: 0.9329\n",
      "Epoch 24/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1497 - accuracy: 0.9319 - val_loss: 0.1693 - val_accuracy: 0.9265\n",
      "Epoch 25/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1686 - accuracy: 0.9311 - val_loss: 0.1364 - val_accuracy: 0.9333\n",
      "Epoch 26/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1441 - accuracy: 0.9327 - val_loss: 0.1350 - val_accuracy: 0.9331\n",
      "Epoch 27/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1434 - accuracy: 0.9328 - val_loss: 0.1352 - val_accuracy: 0.9331\n",
      "Epoch 28/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1439 - accuracy: 0.9329 - val_loss: 0.1356 - val_accuracy: 0.9335\n",
      "Epoch 29/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1439 - accuracy: 0.9330 - val_loss: 0.1356 - val_accuracy: 0.9334\n",
      "Epoch 30/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1429 - accuracy: 0.9334 - val_loss: 0.1355 - val_accuracy: 0.9326\n",
      "Epoch 31/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1434 - accuracy: 0.9332 - val_loss: 0.1355 - val_accuracy: 0.9332\n",
      "Epoch 32/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1429 - accuracy: 0.9332 - val_loss: 0.1352 - val_accuracy: 0.9337\n",
      "Epoch 33/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1428 - accuracy: 0.9334 - val_loss: 0.1354 - val_accuracy: 0.9326\n",
      "Epoch 34/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1428 - accuracy: 0.9335 - val_loss: 0.1351 - val_accuracy: 0.9332\n",
      "Epoch 35/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1428 - accuracy: 0.9334 - val_loss: 0.1354 - val_accuracy: 0.9327\n",
      "Epoch 36/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1428 - accuracy: 0.9335 - val_loss: 0.1359 - val_accuracy: 0.9334\n",
      "Epoch 37/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1427 - accuracy: 0.9335 - val_loss: 0.1352 - val_accuracy: 0.9331\n",
      "Epoch 38/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1430 - accuracy: 0.9337 - val_loss: 0.1355 - val_accuracy: 0.9331\n",
      "Epoch 39/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1428 - accuracy: 0.9335 - val_loss: 0.1353 - val_accuracy: 0.9330\n",
      "Epoch 40/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1427 - accuracy: 0.9337 - val_loss: 0.1352 - val_accuracy: 0.9335\n",
      "Epoch 41/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1427 - accuracy: 0.9335 - val_loss: 0.1355 - val_accuracy: 0.9326\n",
      "Epoch 42/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1427 - accuracy: 0.9337 - val_loss: 0.1360 - val_accuracy: 0.9330\n",
      "Epoch 43/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.2602 - accuracy: 0.9264 - val_loss: 0.2905 - val_accuracy: 0.9237\n",
      "Epoch 44/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.3459 - accuracy: 0.9210 - val_loss: 0.2903 - val_accuracy: 0.9238\n",
      "Epoch 45/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.3456 - accuracy: 0.9213 - val_loss: 0.2902 - val_accuracy: 0.9234\n",
      "Epoch 46/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.3456 - accuracy: 0.9211 - val_loss: 0.2897 - val_accuracy: 0.9233\n",
      "Epoch 47/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.3456 - accuracy: 0.9210 - val_loss: 0.2896 - val_accuracy: 0.9236\n",
      "Epoch 48/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.3456 - accuracy: 0.9213 - val_loss: 0.2895 - val_accuracy: 0.9241\n",
      "Epoch 49/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.3456 - accuracy: 0.9211 - val_loss: 0.2892 - val_accuracy: 0.9237\n",
      "Epoch 50/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.3456 - accuracy: 0.9211 - val_loss: 0.2900 - val_accuracy: 0.9239\n",
      "Epoch 51/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.3214 - accuracy: 0.9225 - val_loss: 0.1359 - val_accuracy: 0.9331\n",
      "Epoch 52/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1432 - accuracy: 0.9338 - val_loss: 0.1350 - val_accuracy: 0.9329\n",
      "Epoch 53/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1427 - accuracy: 0.9338 - val_loss: 0.1358 - val_accuracy: 0.9335\n",
      "Epoch 54/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1426 - accuracy: 0.9338 - val_loss: 0.1359 - val_accuracy: 0.9333\n",
      "Epoch 55/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1426 - accuracy: 0.9340 - val_loss: 0.1360 - val_accuracy: 0.9333\n",
      "Epoch 56/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1447 - accuracy: 0.9339 - val_loss: 0.1347 - val_accuracy: 0.9333\n",
      "Epoch 57/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1426 - accuracy: 0.9341 - val_loss: 0.1358 - val_accuracy: 0.9329\n",
      "Epoch 58/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1495 - accuracy: 0.9328 - val_loss: 0.1356 - val_accuracy: 0.9339\n",
      "Epoch 59/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1437 - accuracy: 0.9339 - val_loss: 0.1363 - val_accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1426 - accuracy: 0.9337 - val_loss: 0.1351 - val_accuracy: 0.9332\n",
      "Epoch 61/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1426 - accuracy: 0.9339 - val_loss: 0.1347 - val_accuracy: 0.9334\n",
      "Epoch 62/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1426 - accuracy: 0.9339 - val_loss: 0.1352 - val_accuracy: 0.9333\n",
      "Epoch 63/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1426 - accuracy: 0.9341 - val_loss: 0.1356 - val_accuracy: 0.9332\n",
      "Epoch 64/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1426 - accuracy: 0.9336 - val_loss: 0.1360 - val_accuracy: 0.9333\n",
      "Epoch 65/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1426 - accuracy: 0.9337 - val_loss: 0.1353 - val_accuracy: 0.9331\n",
      "Epoch 66/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9340 - val_loss: 0.1361 - val_accuracy: 0.9328\n",
      "Epoch 67/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9341 - val_loss: 0.1360 - val_accuracy: 0.9335\n",
      "Epoch 68/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1425 - accuracy: 0.9340 - val_loss: 0.1362 - val_accuracy: 0.9333\n",
      "Epoch 69/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1427 - accuracy: 0.9338 - val_loss: 0.1352 - val_accuracy: 0.9334\n",
      "Epoch 70/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1438 - accuracy: 0.9336 - val_loss: 0.1352 - val_accuracy: 0.9335\n",
      "Epoch 71/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1429 - accuracy: 0.9340 - val_loss: 0.1357 - val_accuracy: 0.9329\n",
      "Epoch 72/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9342 - val_loss: 0.1357 - val_accuracy: 0.9332\n",
      "Epoch 73/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1425 - accuracy: 0.9341 - val_loss: 0.1352 - val_accuracy: 0.9328\n",
      "Epoch 74/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9339 - val_loss: 0.1357 - val_accuracy: 0.9338\n",
      "Epoch 75/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9341 - val_loss: 0.1364 - val_accuracy: 0.9331\n",
      "Epoch 76/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1425 - accuracy: 0.9339 - val_loss: 0.1361 - val_accuracy: 0.9332\n",
      "Epoch 77/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9341 - val_loss: 0.1354 - val_accuracy: 0.9332\n",
      "Epoch 78/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1436 - accuracy: 0.9340 - val_loss: 0.1360 - val_accuracy: 0.9333\n",
      "Epoch 79/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9340 - val_loss: 0.1354 - val_accuracy: 0.9333\n",
      "Epoch 80/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1464 - accuracy: 0.9335 - val_loss: 0.1362 - val_accuracy: 0.9333\n",
      "Epoch 81/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1426 - accuracy: 0.9339 - val_loss: 0.1361 - val_accuracy: 0.9336\n",
      "Epoch 82/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1425 - accuracy: 0.9341 - val_loss: 0.1352 - val_accuracy: 0.9331\n",
      "Epoch 83/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1425 - accuracy: 0.9340 - val_loss: 0.1359 - val_accuracy: 0.9331\n",
      "Epoch 84/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1425 - accuracy: 0.9338 - val_loss: 0.1352 - val_accuracy: 0.9330\n",
      "Epoch 85/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1425 - accuracy: 0.9338 - val_loss: 0.1350 - val_accuracy: 0.9335\n",
      "Epoch 86/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1443 - accuracy: 0.9338 - val_loss: 0.1366 - val_accuracy: 0.9327\n",
      "Epoch 87/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1428 - accuracy: 0.9340 - val_loss: 0.1361 - val_accuracy: 0.9336\n",
      "Epoch 88/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1426 - accuracy: 0.9339 - val_loss: 0.1360 - val_accuracy: 0.9332\n",
      "Epoch 89/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1441 - accuracy: 0.9339 - val_loss: 0.1358 - val_accuracy: 0.9334\n",
      "Epoch 90/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1425 - accuracy: 0.9340 - val_loss: 0.1351 - val_accuracy: 0.9331\n",
      "Epoch 91/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9340 - val_loss: 0.1364 - val_accuracy: 0.9328\n",
      "Epoch 92/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1425 - accuracy: 0.9341 - val_loss: 0.1357 - val_accuracy: 0.9331\n",
      "Epoch 93/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1425 - accuracy: 0.9342 - val_loss: 0.1354 - val_accuracy: 0.9334\n",
      "Epoch 94/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1433 - accuracy: 0.9339 - val_loss: 0.1357 - val_accuracy: 0.9334\n",
      "Epoch 95/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9342 - val_loss: 0.1354 - val_accuracy: 0.9325\n",
      "Epoch 96/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1425 - accuracy: 0.9337 - val_loss: 0.1352 - val_accuracy: 0.9334\n",
      "Epoch 97/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1425 - accuracy: 0.9340 - val_loss: 0.1356 - val_accuracy: 0.9327\n",
      "Epoch 98/100\n",
      "508/508 [==============================] - 13s 27ms/step - loss: 0.1425 - accuracy: 0.9339 - val_loss: 0.1358 - val_accuracy: 0.9335\n",
      "Epoch 99/100\n",
      "508/508 [==============================] - 13s 26ms/step - loss: 0.1429 - accuracy: 0.9340 - val_loss: 0.1352 - val_accuracy: 0.9335\n",
      "Epoch 100/100\n",
      "508/508 [==============================] - 14s 27ms/step - loss: 0.1431 - accuracy: 0.9338 - val_loss: 0.1357 - val_accuracy: 0.9330\n"
     ]
    }
   ],
   "source": [
    "# Encoder RNN\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(None, num_encoder_tokens+1))\n",
    "encoder = tf.keras.layers.LSTM(rnn_size, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder RNN\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None, num_decoder_tokens+1))\n",
    "decoder_lstm = tf.keras.layers.LSTM(rnn_size, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense = tf.keras.layers.Dense(num_decoder_tokens+1, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Seq2seq Model\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,batch_size=batch_size,epochs=epochs,validation_split=0.2)\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7G9ZWF2MuKSS"
   },
   "outputs": [],
   "source": [
    "# Inference mode (sampling).\n",
    "\n",
    "encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_size,))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = tf.keras.models.Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states)\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens+1))\n",
    "    target_seq[0, 0, target_token_index['bos']] = 1.\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_target_token[sampled_token_index]\n",
    "        if (sampled_char == 'eos'):\n",
    "          decoded_sentence += '.'\n",
    "          stop_condition = True\n",
    "        else:\n",
    "          decoded_sentence += sampled_char +' '\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens+1))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dtG_hBJ3xvjS",
    "outputId": "44027917-4d81-4ab6-a05e-9ce8bfd388ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: hello\n",
      "Decoded sentence: hello what can i help you with today .\n",
      "-\n",
      "Input sentence: can you book a table for six people with french food\n",
      "Decoded sentence: i'm on it .\n",
      "-\n",
      "Input sentence: <SILENCE>\n",
      "Decoded sentence: apicall italian paris six cheap .\n",
      "-\n",
      "Input sentence: in bombay\n",
      "Decoded sentence: how many people would be   your party .\n",
      "-\n",
      "Input sentence: i am looking for a cheap restaurant\n",
      "Decoded sentence: ok let me look into some options for you .\n",
      "-\n",
      "Input sentence: <SILENCE>\n",
      "Decoded sentence: apicall italian paris six cheap .\n",
      "-\n",
      "Input sentence: hi\n",
      "Decoded sentence: hello what can i help you with today .\n",
      "-\n",
      "Input sentence: can you make a restaurant reservation with italian cuisine for six people in a cheap price range\n",
      "Decoded sentence: i'm on it .\n",
      "-\n",
      "Input sentence: <SILENCE>\n",
      "Decoded sentence: apicall italian paris six cheap .\n",
      "-\n",
      "Input sentence: rome please\n",
      "Decoded sentence: how many people would be   your party .\n",
      "-\n",
      "Input sentence: <SILENCE>\n",
      "Decoded sentence: apicall italian paris six cheap .\n",
      "-\n",
      "Input sentence: good morning\n",
      "Decoded sentence: hello what can i help you with today .\n",
      "-\n",
      "Input sentence: may i have a table with british cuisine in a cheap price range in london\n",
      "Decoded sentence: i'm on it .\n",
      "-\n",
      "Input sentence: <SILENCE>\n",
      "Decoded sentence: apicall italian paris six cheap .\n",
      "-\n",
      "Input sentence: for four please\n",
      "Decoded sentence: which price range are looking for .\n",
      "-\n",
      "Input sentence: <SILENCE>\n",
      "Decoded sentence: apicall italian paris six cheap .\n",
      "-\n",
      "Input sentence: good morning\n",
      "Decoded sentence: hello what can i help you with today .\n",
      "-\n",
      "Input sentence: i'd like to book a table in london\n",
      "Decoded sentence: i'm on it .\n",
      "-\n",
      "Input sentence: <SILENCE>\n",
      "Decoded sentence: apicall italian paris six cheap .\n",
      "-\n",
      "Input sentence: with british cuisine\n",
      "Decoded sentence: where should it be .\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(20):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', user_utterances[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "8A0GQpxyvUsa",
    "outputId": "39c6fccf-ff7f-449f-8d5a-f8f64da0d0aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hello\n",
      "ChatBot: hello what can i help you with today .\n",
      "You: book a table for two\n",
      "ChatBot: i'm on it .\n",
      "You: Goodbye\n"
     ]
    }
   ],
   "source": [
    "# Setting up the chat\n",
    "while(True):\n",
    "  user_input = []\n",
    "  user_input = input(\"You: \")\n",
    "  if(user_input == \"Goodbye\"):\n",
    "    break\n",
    "  input_seqn = np.zeros((1, max_encoder_seq_length, num_encoder_tokens+1),dtype='float32')\n",
    "  for t, word in enumerate(user_input.split()):\n",
    "    input_seqn[0, t, input_token_index[word]] = 1.\n",
    "  input_seqn[0, t + 1:, input_token_index[' ']] = 1.\n",
    "  decoded_sentence = decode_sequence(input_seqn)\n",
    "  print('ChatBot: ' + decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpmRPBM9ZFNk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2Seq_WithoutAttention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
